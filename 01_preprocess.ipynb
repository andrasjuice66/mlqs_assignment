{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:57:10.993175Z",
     "iopub.status.busy": "2024-05-02T19:57:10.992192Z",
     "iopub.status.idle": "2024-05-02T19:57:11.714611Z",
     "shell.execute_reply": "2024-05-02T19:57:11.714212Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time\n",
    "from src.OutlierDetection import DistanceBasedOutlierDetection\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from matplotlib.legend_handler import HandlerPathCollection\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from util.plot_util import plot_lof_2d_grad, plot_lof_2d_circle, plot_lof_3d_grad ,plot_lof_3d_circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_start_end(df, secs=5):\n",
    "    return df[(df[\"Time (s)\"] > secs) & (df[\"Time (s)\"] < max(df[\"Time (s)\"]) - secs)]\n",
    "\n",
    "def calculate_lof(df, cols, label):\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.2)\n",
    "    #X = df[cols].values\n",
    "    y_pred = lof.fit_predict(df[cols])\n",
    "    \n",
    "    df[f'lof_{label}'] = y_pred\n",
    "    df[f'lof_factor_{label}'] = -lof.negative_outlier_factor_  # Negate to align with typical plotting conventions\n",
    "    return df\n",
    "\n",
    "def outlier_search(df, cols, method='lof'):\n",
    "    for col in cols:\n",
    "        if method == 'lof':\n",
    "            df = calculate_lof(df, cols)\n",
    "        elif method == 'zscore':\n",
    "            z_scores = stats.zscore(df[col])\n",
    "            df.loc[abs(z_scores) > 3, col] = np.nan\n",
    "        elif method == 'iqr':\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            df.loc[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)), col] = np.nan\n",
    "    if method == 'lof':\n",
    "        df.loc[df['lof'] == -1, cols] = np.nan\n",
    "    df[cols].interpolate(method='linear', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking\n",
      "Walking QS 2024-06-04 14-52-10\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'Datetime_y'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m velocity_col \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mVelocity (m/s)\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     30\u001b[0m linacc_cols \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mLinear Acceleration x (m/s^2)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLinear Acceleration y (m/s^2)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLinear Acceleration z (m/s^2)\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 32\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge_asof(linacc, pd\u001b[39m.\u001b[39;49mmerge_asof(loc, pd\u001b[39m.\u001b[39;49mmerge_asof(acc, gyro, on\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTime (s)\u001b[39;49m\u001b[39m\"\u001b[39;49m, direction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnearest\u001b[39;49m\u001b[39m\"\u001b[39;49m), on\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTime (s)\u001b[39;49m\u001b[39m\"\u001b[39;49m, direction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnearest\u001b[39;49m\u001b[39m\"\u001b[39;49m), on\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTime (s)\u001b[39;49m\u001b[39m\"\u001b[39;49m, direction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnearest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     35\u001b[0m \u001b[39m#PLOTTING\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# Detect and remove outliers for accelerometer data\u001b[39;00m\n\u001b[1;32m     37\u001b[0m df \u001b[39m=\u001b[39m calculate_lof(df, acc_cols, \u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/AI_masters/Period_6/MLQS/MLQS_assignment/env/lib/python3.9/site-packages/pandas/core/reshape/merge.py:708\u001b[0m, in \u001b[0;36mmerge_asof\u001b[0;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39mPerform a merge by key distance.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39m4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    691\u001b[0m op \u001b[39m=\u001b[39m _AsOfMerge(\n\u001b[1;32m    692\u001b[0m     left,\n\u001b[1;32m    693\u001b[0m     right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    706\u001b[0m     direction\u001b[39m=\u001b[39mdirection,\n\u001b[1;32m    707\u001b[0m )\n\u001b[0;32m--> 708\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/Documents/AI_masters/Period_6/MLQS/MLQS_assignment/env/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1946\u001b[0m, in \u001b[0;36m_OrderedMerge.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1944\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfill_method must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mffill\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1946\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[1;32m   1947\u001b[0m     join_index, left_join_indexer, right_join_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[1;32m   1948\u001b[0m )\n\u001b[1;32m   1949\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_add_join_keys(result, left_indexer, right_indexer)\n\u001b[1;32m   1951\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/AI_masters/Period_6/MLQS/MLQS_assignment/env/lib/python3.9/site-packages/pandas/core/reshape/merge.py:840\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    837\u001b[0m left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft[:]\n\u001b[1;32m    838\u001b[0m right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright[:]\n\u001b[0;32m--> 840\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    841\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuffixes\n\u001b[1;32m    842\u001b[0m )\n\u001b[1;32m    844\u001b[0m \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[39mlen\u001b[39m(left)):\n\u001b[1;32m    845\u001b[0m     \u001b[39m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    846\u001b[0m     \u001b[39m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[39m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     lmgr \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[1;32m    849\u001b[0m         join_index,\n\u001b[1;32m    850\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m         use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    856\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/AI_masters/Period_6/MLQS/MLQS_assignment/env/lib/python3.9/site-packages/pandas/core/reshape/merge.py:2757\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2755\u001b[0m     dups\u001b[39m.\u001b[39mextend(rlabels[(rlabels\u001b[39m.\u001b[39mduplicated()) \u001b[39m&\u001b[39m (\u001b[39m~\u001b[39mright\u001b[39m.\u001b[39mduplicated())]\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m   2756\u001b[0m \u001b[39mif\u001b[39;00m dups:\n\u001b[0;32m-> 2757\u001b[0m     \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[1;32m   2758\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing \u001b[39m\u001b[39m'\u001b[39m\u001b[39msuffixes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m which cause duplicate columns \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mset\u001b[39m(dups)\u001b[39m}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2759\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnot allowed.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2760\u001b[0m     )\n\u001b[1;32m   2762\u001b[0m \u001b[39mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'Datetime_y'} is not allowed."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for cat in [\"Walking\", \"Sitting\", \"Cycling\", \"Sport\"]:\n",
    "        print(cat)\n",
    "        for f in os.listdir(\"data_1/\"):\n",
    "            if cat in f:\n",
    "                for subf in os.listdir(\"data_1/\" + f):\n",
    "                    start_time = time.time()\n",
    "                    print(f, subf)\n",
    "                    acc = pd.read_csv(\"data_1/\" + f + \"/\" + subf + \"/Accelerometer.csv\")\n",
    "                    loc = pd.read_csv(\"data_1/\" + f + \"/\" + subf + \"/Location.csv\")\n",
    "                    gyro = pd.read_csv(\"data_1/\" + f + \"/\" + subf + \"/Gyroscope.csv\")\n",
    "                    linacc = pd.read_csv(\"data_1/\" + f + \"/\" + subf + \"/Linear Acceleration.csv\")\n",
    "\n",
    "                    cols = [\"Acceleration x (m/s^2)\", \"Acceleration y (m/s^2)\", \"Acceleration z (m/s^2)\",\n",
    "                            \"Gyroscope x (rad/s)\", \"Gyroscope y (rad/s)\", \"Gyroscope z (rad/s)\",\n",
    "                            \"Velocity (m/s)\", \"Height (m)\", \"Linear Acceleration x (m/s^2)\", \n",
    "                            \"Linear Acceleration y (m/s^2)\", \"Linear Acceleration z (m/s^2)\"]\n",
    "\n",
    "                    acc = remove_start_end(acc)\n",
    "                    loc = remove_start_end(loc)\n",
    "                    gyro = remove_start_end(gyro)\n",
    "                    linacc = remove_start_end(linacc)\n",
    "\n",
    "                    \n",
    "                    acc_cols = [\"Acceleration x (m/s^2)\", \"Acceleration y (m/s^2)\", \"Acceleration z (m/s^2)\", \"Time (s)\"]\n",
    "                    loc_cols = [\"Latitude (째)\", \"Longitude (째)\", \"Time (s)\"]\n",
    "                    loc_height_col = [\"Latitude (째)\", \"Longitude (째)\", \"Height (m)\", \"Time (s)\"]\n",
    "                    gyro_cols = ['Gyroscope x (rad/s)', 'Gyroscope y (rad/s)', 'Gyroscope z (rad/s)', \"Time (s)\"]\n",
    "                    velocity_col = [\"Velocity (m/s)\"]\n",
    "                    linacc_cols = [\"Linear Acceleration x (m/s^2)\", \"Linear Acceleration y (m/s^2)\", \"Linear Acceleration z (m/s^2)\"]\n",
    "                    \n",
    "                    df = pd.merge_asof(linacc, pd.merge_asof(loc, pd.merge_asof(acc, gyro, on=\"Time (s)\", direction=\"nearest\"), on=\"Time (s)\", direction=\"nearest\"), on=\"Time (s)\", direction=\"nearest\")\n",
    "\n",
    "\n",
    "                    #PLOTTING\n",
    "                    # Detect and remove outliers for accelerometer data\n",
    "                    df = calculate_lof(df, acc_cols, 'acc')\n",
    "                    df = calculate_lof(df, gyro_cols, 'gyro')\n",
    "                    df = calculate_lof(df, loc_cols, 'loc')\n",
    "                    df = calculate_lof(df, linacc_cols, 'linacc')\n",
    "\n",
    "                    # PLOTTING\n",
    "                    plot_lof_3d_grad(df, acc_cols, cat)\n",
    "                    # plot_lof_3d_grad(df, gyro_cols, cat)\n",
    "                    # plot_lof_2d_grad(df, loc_cols, cat)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c7853a7f6380c5c652c4ecade97f8ac7cc0e9eab34a6ddd88c01f0f43192157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
